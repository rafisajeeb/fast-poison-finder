{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d0757e",
   "metadata": {},
   "source": [
    "\n",
    "# Fast Poison-Point Finder â€” Jupyter Walkthrough\n",
    "\n",
    "This notebook walks you through the **#7 Fast Poison-Point Finder** pipeline using CIFAR-10:\n",
    "1. Environment check\n",
    "2. Create poisoned indices (10% blended trigger)\n",
    "3. Train clean & poisoned models\n",
    "4. Evaluate clean accuracy & attack success rate (ASR)\n",
    "5. Compute embeddings\n",
    "6. Rank suspicious samples (Mahalanobis, LOF, Fusion)\n",
    "7. Evaluate Precision@k\n",
    "8. (Optional) Plot results\n",
    "\n",
    "> Tip: Run this notebook from inside the project folder after installing requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4ed33",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Environment setup (run locally on your machine)\n",
    "Open a terminal in the project folder and run:\n",
    "```bash\n",
    "python -m venv .venv\n",
    "# Linux/Mac:\n",
    "source .venv/bin/activate\n",
    "# Windows (PowerShell):\n",
    "# .venv\\Scripts\\Activate.ps1\n",
    "\n",
    "pip install -r requirements.txt\n",
    "pip install jupyter\n",
    "jupyter lab   # or: jupyter notebook\n",
    "```\n",
    "Then open this notebook (`FastPoisonFinder.ipynb`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de35b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Sanity check: Python, Torch, and device\n",
    "import torch, torchvision\n",
    "#print(\"Torch:\", torch.__version__, \"Torchvision:\", torchvision.__version__)\n",
    "#print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110fd77",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Create poisoned indices\n",
    "Pick 10% of CIFAR-10 training images to poison and set the target class to `0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c402f1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\\\Users\\\\rafir\\\\scripts\\\\make_poison_indices.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python scripts/make_poison_indices.py --poison-rate 0.10 --target-class 0 --seed 1 --out data/poisoned_blended_p10_s1.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74468c6d",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Train models\n",
    "- Clean model (no poisoning)\n",
    "- Poisoned model (applies blended white-square trigger, re-labels to target class during training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4827da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This will auto-download CIFAR-10 the first time\n",
    "!python scripts/train_model.py --epochs 40 --save ckpt/clean_resnet18.pth\n",
    "!python scripts/train_model.py --epochs 40 --poison-indices data/poisoned_blended_p10_s1.json --save ckpt/poisoned_resnet18.pth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a7a75",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Evaluate Clean Accuracy and Attack Success Rate (ASR)\n",
    "ASR is measured by adding the trigger to **all test images** and checking how often the model predicts the target class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python scripts/eval_asr.py --model ckpt/clean_resnet18.pth\n",
    "!python scripts/eval_asr.py --model ckpt/poisoned_resnet18.pth --target 0 --size 5 --alpha 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39aa2e",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Compute embeddings for the (poisoned) training set\n",
    "We use a frozen ImageNet ResNet-18 backbone and cache embeddings/labels/indices to a `.npz` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc469eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python scripts/compute_embeddings.py --poison-indices data/poisoned_blended_p10_s1.json --out data/embeddings_blended_p10_s1.npz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d573418",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Rank suspicious samples\n",
    "Try **Mahalanobis**, **LOF**, and **Fusion** (equal weights). Save Top-200 indices for each method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb46d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python scripts/rank_suspicious.py --embeddings data/embeddings_blended_p10_s1.npz --method mahalanobis --topk 200 --out data/rank_mahal_top200.json\n",
    "!python scripts/rank_suspicious.py --embeddings data/embeddings_blended_p10_s1.npz --method lof         --topk 200 --out data/rank_lof_top200.json\n",
    "!python scripts/rank_suspicious.py --embeddings data/embeddings_blended_p10_s1.npz --method fusion      --topk 200 --out data/rank_fusion_top200.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad9143",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Evaluate Precision@k\n",
    "Compares top-k ranked indices to the ground-truth poisoned indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python scripts/eval_precision.py --rank data/rank_mahal_top200.json --poison-indices data/poisoned_blended_p10_s1.json --k 200\n",
    "!python scripts/eval_precision.py --rank data/rank_lof_top200.json   --poison-indices data/poisoned_blended_p10_s1.json --k 200\n",
    "!python scripts/eval_precision.py --rank data/rank_fusion_top200.json --poison-indices data/poisoned_blended_p10_s1.json --k 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5be26d",
   "metadata": {},
   "source": [
    "\n",
    "## 7) (Optional) Quick plots\n",
    "P@k curve for different methods and a bar chart for Clean Acc vs. ASR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4050f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting helper for Precision@k if you saved ranked lists for multiple k values\n",
    "import json, matplotlib.pyplot as plt, numpy as np\n",
    "\n",
    "def precision_at_k(ranked_indices, poisoned_set, k):\n",
    "    return len(set(ranked_indices[:k]).intersection(poisoned_set))/k\n",
    "\n",
    "poison_meta = json.load(open(\"data/poisoned_blended_p10_s1.json\"))\n",
    "poisoned = set(poison_meta[\"indices\"])\n",
    "\n",
    "methods = [\"rank_mahal_top200.json\",\"rank_lof_top200.json\",\"rank_fusion_top200.json\"]\n",
    "labels  = [\"Mahalanobis\",\"LOF\",\"Fusion\"]\n",
    "ks = [50,100,200]\n",
    "vals = []\n",
    "\n",
    "for fn in methods:\n",
    "    j = json.load(open(\"data/\"+fn))\n",
    "    ranked = j[\"indices_ranked\"]\n",
    "    vals.append([precision_at_k(ranked, poisoned, k) for k in ks])\n",
    "\n",
    "vals = np.array(vals)\n",
    "\n",
    "for i, lab in enumerate(labels):\n",
    "    plt.plot(ks, vals[i], marker='o', label=lab)\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Precision@k\"); plt.title(\"Precision@k on Blended-10%\"); plt.legend(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
